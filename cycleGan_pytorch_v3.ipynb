{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#!gdown --id 1yhbk1BJUAnL6_XXYL2KC5u7k7JzGMu3I"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#!unzip RainTrainH.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:20:22.898784Z","iopub.status.busy":"2023-07-22T13:20:22.898015Z","iopub.status.idle":"2023-07-22T13:20:26.131225Z","shell.execute_reply":"2023-07-22T13:20:26.130220Z","shell.execute_reply.started":"2023-07-22T13:20:22.898751Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","import torchvision.transforms as transforms\n","#from torchvision.utils import make_grid\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data (path)\n","#dataset_name = 'RainTrainH'\n","#root = './'+dataset_name\n","\n","N_CPU = 1\n","# data (img)\n","IMG_HEIGHT = 512\n","IMG_WIDTH = 512\n","CHANNELS = 3\n","\n","# training\n","EPOCH_START = 0 # epoch to start training from\n","EPOCH_NUM   = 50 # number of epochs of training\n","BATCH_SIZE = 1 # size of the batches\n","LR = 0.0002 # adam : learning rate\n","BETA1 = 0.5 # adam : decay of first order momentum of gradient\n","BETA2 = 0.999 # adam : decay of first order momentum of gradient\n","EPOCH_DECAY = 25 # suggested default : 100 (suggested 'n_epochs' is 200)\n","                 # epoch from which to start lr decay"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 1. read Data from folder"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:20:26.187772Z","iopub.status.busy":"2023-07-22T13:20:26.186811Z","iopub.status.idle":"2023-07-22T13:20:26.197248Z","shell.execute_reply":"2023-07-22T13:20:26.196317Z","shell.execute_reply.started":"2023-07-22T13:20:26.187738Z"},"trusted":true},"outputs":[],"source":["print(\"======================read Data from folder===============================\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 2-a load data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:20:31.290396Z","iopub.status.busy":"2023-07-22T13:20:31.289625Z","iopub.status.idle":"2023-07-22T13:20:31.303663Z","shell.execute_reply":"2023-07-22T13:20:31.302599Z","shell.execute_reply.started":"2023-07-22T13:20:31.290349Z"},"trusted":true},"outputs":[],"source":["import glob\n","import os\n","#######################################################################################\n","def load_train_data(img_path, n_len, valid_ratio=0.12):\n","    train_image = [i for i in sorted(glob.glob(os.path.join(img_path, \"*.*\")))]\n","    train_data = list(zip(train_image))\n","    #np.random.seed(1234)\n","    #np.random.shuffle(train_data)\n","    #split_len = int(len(train_data) * valid_ratio)\n","    #print(\"split_len: \",split_len)\n","    \n","    train_set = train_data\n","    valid_set = train_data[:n_len]\n","    \n","    return train_set, valid_set\n","#######################################################################################\n","def load_test_data(img_path):\n","    test_image = [i for i in sorted(glob.glob(os.path.join(img_path, \"*.*\")))]\n","    test_data = list(zip(test_image))\n","    test_set = test_data\n","    return test_set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:15.609129Z","iopub.status.busy":"2023-07-22T13:21:15.608696Z","iopub.status.idle":"2023-07-22T13:21:15.859779Z","shell.execute_reply":"2023-07-22T13:21:15.858773Z","shell.execute_reply.started":"2023-07-22T13:21:15.609092Z"},"trusted":true},"outputs":[],"source":["import glob\n","import os\n","TRA_PATHA = \"./RainTrainH/train/rainy_image\"\n","TRA_PATHB = \"./RainTrainH/train/ground_truth\"\n","TST_PATHA = \"./RainTrainH/test/rainy_image\"\n","TST_PATHB = \"./RainTrainH/test/ground_truth\"\n","CKP_PATHA = \"\"\n","trainA_set, validA_set = load_train_data(TRA_PATHA,n_len=300)\n","trainB_set, validB_set = load_train_data(TRA_PATHB,n_len=50)\n","testA_set = load_test_data(TST_PATHA)\n","\n","#trainB_set, validB_set = load_train_data(TRA_PATHB)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(validA_set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(validB_set)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 2-b custom datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:20.187333Z","iopub.status.busy":"2023-07-22T13:21:20.186109Z","iopub.status.idle":"2023-07-22T13:21:20.193409Z","shell.execute_reply":"2023-07-22T13:21:20.192405Z","shell.execute_reply.started":"2023-07-22T13:21:20.187284Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","import torchvision.transforms as transforms\n","\n","transforms_train = [\n","    #transforms.Resize(int(img_height*1.12), Image.BICUBIC),\n","    #transforms.RandomCrop((IMG_HEIGHT//16, IMG_WIDTH//16)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","]\n","transforms_train = transforms.Compose(transforms_train)\n","\n","transforms_test = [\n","    #transforms.Resize(int(img_height*1.12), Image.BICUBIC),\n","    #transforms.RandomCrop((img_height, img_width)),\n","    #transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","]\n","transforms_test = transforms.Compose(transforms_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:18.233232Z","iopub.status.busy":"2023-07-22T13:21:18.232498Z","iopub.status.idle":"2023-07-22T13:21:18.249770Z","shell.execute_reply":"2023-07-22T13:21:18.248458Z","shell.execute_reply.started":"2023-07-22T13:21:18.233195Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","#######################################################################################\n","class TraValDataset(Dataset):\n","    def __init__(self, dataA, dataB, augment=None, unaligned=False):\n","        self.dataA      = dataA\n","        self.dataB      = dataB\n","        self.augment   = augment\n","        self.unaligned = unaligned\n","\n","    def __len__(self):\n","        return max(len(self.dataA), len(self.dataB))\n","    \n","    def normalize(img):\n","        # TODO: do normalization there\n","        pass\n","    \n","    def read_img(self, path):\n","        img = Image.open(path).convert('RGB')\n","        #img = img.resize((224,224))\n","        #img = transforms.Resize([256,256])(img)\n","        #img = transforms.Pad(32, padding_mode='symmetric')(img)\n","        if (max(IMG_WIDTH,IMG_HEIGHT)>=max(img.size[1],img.size[0])):\n","            pad_h    = (IMG_WIDTH-img.size[1])//2\n","            pad_h_r  = (IMG_WIDTH-img.size[1])%2\n","            pad_w    = (IMG_HEIGHT-img.size[0])//2\n","            pad_w_r  = (IMG_HEIGHT-img.size[0])%2\n","            img_pad  = transforms.Pad(( pad_w, pad_h, pad_w+pad_w_r, pad_h+pad_h_r), fill=255, padding_mode=\"constant\")(img)\n","        else:\n","            img_pad  = img \n","        if not self.augment is None:\n","            img_aug = self.augment(img_pad)\n","        else:\n","            img_aug = img_pad\n","         \n","        return img_aug\n","    \n","    def __getitem__(self, idx):\n","        img_realX = self.read_img(self.dataA[idx % len(self.dataA)][0])\n","        if self.unaligned:\n","            #image_B = Image.open(self.files_B[np.random.randint(0, len(self.files_B)-1)])\n","            img_realY = self.read_img(self.dataB[idx//6][0])\n","        else:\n","            img_realY = self.read_img(self.dataB[idx % len(self.dataB)][0])\n","        return {'A': img_realX, 'B': img_realY}\n","    \n","#######################################################################################\n","class TestDataset(Dataset):\n","    def __init__(self, dataA, augment=None, unaligned=False):\n","        self.dataA      = dataA\n","        self.augment   = augment\n","\n","    def __len__(self):\n","        return len(self.dataA)\n","    \n","    def normalize(img):\n","        # TODO: do normalization there\n","        pass\n","    \n","    def read_img(self, path):\n","        img = Image.open(path).convert('RGB')\n","        #img = img.resize((224,224))\n","        #img = transforms.Resize([256,256])(img)\n","        #img = transforms.Pad(32, padding_mode='symmetric')(img)\n","        if (max(IMG_WIDTH,IMG_HEIGHT)>=max(img.size[1],img.size[0])):\n","            pad_h    = (IMG_WIDTH-img.size[1])//2\n","            pad_h_r  = (IMG_WIDTH-img.size[1])%2\n","            pad_w    = (IMG_HEIGHT-img.size[0])//2\n","            pad_w_r  = (IMG_HEIGHT-img.size[0])%2\n","            img_pad  = transforms.Pad(( pad_w, pad_h, pad_w+pad_w_r, pad_h+pad_h_r), fill=255, padding_mode=\"constant\")(img)\n","        else:\n","            img_pad  = img \n","        if not self.augment is None:\n","            img_aug = self.augment(img_pad)\n","        else:\n","            img_aug = img_pad\n","        return img_aug\n","    \n","    def __getitem__(self, idx):\n","        img_realX = self.read_img(self.dataA[idx % len(self.dataA)][0])\n","        img_realXName = self.dataA[idx][0].split(\"/\")[-1]\n","        return {'A': img_realX, 'Name': img_realXName}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(512-481)%2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:26.749050Z","iopub.status.busy":"2023-07-22T13:21:26.748597Z","iopub.status.idle":"2023-07-22T13:21:26.755225Z","shell.execute_reply":"2023-07-22T13:21:26.753988Z","shell.execute_reply.started":"2023-07-22T13:21:26.749011Z"},"trusted":true},"outputs":[],"source":["train_dataset = TraValDataset(trainA_set, trainB_set, augment=transforms_train, unaligned=True)#, transform)\n","#trainB_dataset = TraValDataset(trainB_set)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_CPU)\n","#trainB_loader = DataLoader(trainB_dataset, batch_size=16, shuffle=True)\n","\n","valid_dataset = TraValDataset(validA_set, validB_set, augment=transforms_test, unaligned=True)\n","#validB_dataset = TraValDataset(validB_set)\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_CPU)\n","#valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n","\n","test_dataset = TestDataset(testA_set, augment=transforms_test, unaligned=False)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_CPU)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. Module"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 2-a Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:28.301232Z","iopub.status.busy":"2023-07-22T13:21:28.300869Z","iopub.status.idle":"2023-07-22T13:21:28.314799Z","shell.execute_reply":"2023-07-22T13:21:28.313484Z","shell.execute_reply.started":"2023-07-22T13:21:28.301203Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","        \n","        self.block = nn.Sequential(\n","            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n","            nn.Conv2d(in_features, in_features, 3),\n","            nn.InstanceNorm2d(in_features), \n","            nn.ReLU(inplace=True),\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(in_features, in_features, 3),\n","            nn.InstanceNorm2d(in_features)\n","        )\n","\n","    def forward(self, x):\n","        return x + self.block(x)\n","\n","\n","class GeneratorResNet(nn.Module):\n","    def __init__(self, input_shape, num_residual_block):\n","        super(GeneratorResNet, self).__init__()\n","        \n","        channels = input_shape[0]\n","        \n","        # Initial Convolution Block\n","        out_features = 64\n","        model = [\n","            nn.ReflectionPad2d(channels),\n","            nn.Conv2d(channels, out_features, 7),\n","            nn.InstanceNorm2d(out_features),\n","            nn.ReLU(inplace=True)\n","        ]\n","        in_features = out_features\n","        \n","        # Downsampling\n","        for _ in range(2):\n","            out_features *= 2\n","            model += [\n","                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(inplace=True)\n","            ]\n","            in_features = out_features\n","        \n","        # Residual blocks\n","        for _ in range(num_residual_block):\n","            model += [ResidualBlock(out_features)]\n","            \n","        # Upsampling\n","        for _ in range(2):\n","            out_features //= 2\n","            model += [\n","                nn.Upsample(scale_factor=2), # --> width*2, heigh*2\n","                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n","                nn.ReLU(inplace=True)\n","            ]\n","            in_features = out_features\n","            \n","        # Output Layer\n","        model += [nn.ReflectionPad2d(channels),\n","                  nn.Conv2d(out_features, channels, 7),\n","                  nn.Tanh()\n","                 ]\n","        \n","        # Unpacking\n","        self.model = nn.Sequential(*model) \n","        \n","    def forward(self, x):\n","        return self.model(x)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 2-b Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:29.005278Z","iopub.status.busy":"2023-07-22T13:21:29.004005Z","iopub.status.idle":"2023-07-22T13:21:29.014582Z","shell.execute_reply":"2023-07-22T13:21:29.013424Z","shell.execute_reply.started":"2023-07-22T13:21:29.005238Z"},"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Discriminator, self).__init__()\n","        \n","        channels, height, width = input_shape\n","        \n","        # Calculate output shape of image discriminator (PatchGAN)\n","        self.output_shape = (1, height//2**4, width//2**4)\n","        \n","        def discriminator_block(in_filters, out_filters, normalize=True):\n","            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n","            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n","            if normalize:\n","                layers.append(nn.InstanceNorm2d(out_filters))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","        \n","        self.model = nn.Sequential(\n","            *discriminator_block(channels, 64, normalize=False),\n","            *discriminator_block(64, 128),\n","            *discriminator_block(128,256),\n","            *discriminator_block(256,512),\n","            nn.ZeroPad2d((1,0,1,0)),\n","            nn.Conv2d(512, 1, 4, padding=1)\n","        )\n","        \n","    def forward(self, img):\n","        return self.model(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:29.442438Z","iopub.status.busy":"2023-07-22T13:21:29.442021Z","iopub.status.idle":"2023-07-22T13:21:29.447788Z","shell.execute_reply":"2023-07-22T13:21:29.446720Z","shell.execute_reply.started":"2023-07-22T13:21:29.442406Z"},"trusted":true},"outputs":[],"source":["input_shape = (CHANNELS, IMG_HEIGHT, IMG_WIDTH) # (3,256,256)\n","n_residual_blocks = 9 # suggested default, number of residual blocks in generator"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. Loss Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:31.683060Z","iopub.status.busy":"2023-07-22T13:21:31.682693Z","iopub.status.idle":"2023-07-22T13:21:31.691796Z","shell.execute_reply":"2023-07-22T13:21:31.690710Z","shell.execute_reply.started":"2023-07-22T13:21:31.683031Z"},"trusted":true},"outputs":[],"source":["GAN_LOSS      = torch.nn.MSELoss()\n","CYCLE_LOSS    = torch.nn.L1Loss()\n","IDENTITY_LOSS = torch.nn.L1Loss()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4. Train Process"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:21:32.804208Z","iopub.status.busy":"2023-07-22T13:21:32.803528Z","iopub.status.idle":"2023-07-22T13:21:32.809164Z","shell.execute_reply":"2023-07-22T13:21:32.808222Z","shell.execute_reply.started":"2023-07-22T13:21:32.804173Z"},"trusted":true},"outputs":[],"source":["print(\"========================= Train process ===============================\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4-a weight initial"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02) # reset Conv2d's weight(tensor) with Gaussian Distribution\n","        if hasattr(m, 'bias') and m.bias is not None:\n","            torch.nn.init.constant_(m.bias.data, 0.0) # reset Conv2d's bias(tensor) with Constant(0)\n","        elif classname.find('BatchNorm2d') != -1:\n","            torch.nn.init.normal_(m.weight.data, 1.0, 0.02) # reset BatchNorm2d's weight(tensor) with Gaussian Distribution\n","            torch.nn.init.constant_(m.bias.data, 0.0) # reset BatchNorm2d's bias(tensor) with Constant(0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4-b Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:29:26.094632Z","iopub.status.busy":"2023-07-22T13:29:26.094223Z","iopub.status.idle":"2023-07-22T13:29:26.123517Z","shell.execute_reply":"2023-07-22T13:29:26.122526Z","shell.execute_reply.started":"2023-07-22T13:29:26.094601Z"},"trusted":true},"outputs":[],"source":["DEVICE_ID = 0\n","torch.cuda.set_device(DEVICE_ID)\n","USE_GPU = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_GPU else \"cpu\")\n","import torch\n","from torchmetrics.image import StructuralSimilarityIndexMeasure\n","#from piqa import PSNR, SSIM\n","\n","import skimage\n","from skimage.metrics import structural_similarity as SSIM\n","from skimage.metrics import peak_signal_noise_ratio as PSNR\n","################################################################################\n","def train(train_loader, G_AB, G_BA, D_A, D_B, \n","          IDENTITY_LOSS, GAN_LOSS, CYCLE_LOSS,\n","          use_gpu=True):\n","    train_loss = []\n","    #train_acc = []\n","    train_psnr = []\n","    train_ssim = []\n","    for idx, batch in enumerate(tqdm(train_loader)):\n","        if use_gpu:\n","            img_realX = batch['A'].to(device)\n","            img_realY = batch['B'].to(device)\n","            valid = torch.cuda.FloatTensor(np.ones((img_realX.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n","            fake = torch.cuda.FloatTensor(np.zeros((img_realX.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n","        G_AB.train()\n","        G_BA.train()\n","        ####################################\n","        # Generator\n","        optimizer_G.zero_grad()\n","\n","        img_fakeY = G_AB(img_realX)\n","        img_cycledX = G_BA(img_fakeY)\n","        img_fakeX = G_BA(img_realY)\n","        img_cycledY = G_AB(img_fakeX)\n","\n","        disc_realX = D_A(img_realX)\n","        disc_realY = D_B(img_realY)\n","        disc_fakeX = D_A(img_fakeX)\n","        disc_fakeY = D_B(img_fakeY)\n","\n","        # Identity Loss\n","        id_loss_X = IDENTITY_LOSS(img_fakeX, img_realX)\n","        id_loss_Y = IDENTITY_LOSS(img_fakeY, img_realY)\n","        id_loss_t = (id_loss_X+id_loss_Y)/2\n","        # GAN Loss\n","        gan_loss_XY = GAN_LOSS(disc_fakeY, valid)\n","        gan_loss_YX = GAN_LOSS(disc_fakeX, valid)\n","        gan_loss_t  = (gan_loss_XY+gan_loss_YX)/2\n","        # Cycle Loss\n","        cyc_loss_X = CYCLE_LOSS(img_cycledX, img_realX)\n","        cyc_loss_Y = CYCLE_LOSS(img_cycledY, img_realX)\n","        cyc_loss_t = (cyc_loss_X+cyc_loss_Y)/2\n","        # Generator Total Loss\n","        loss_G = (5.0*id_loss_t) + gan_loss_t + (10.0*cyc_loss_t)\n","\n","        loss_G.backward()\n","        optimizer_G.step()\n","        ####################################\n","        # Discriminator A\n","        optimizer_D_A.zero_grad()\n","\n","        real_loss_X = GAN_LOSS(disc_realX, valid)\n","        fake_loss_X = GAN_LOSS(disc_fakeX.detach(), fake)\n","        loss_D_A = (real_loss_X+fake_loss_X)/2\n","        \n","        loss_D_A.backward() \n","        optimizer_D_A.step()\n","        ####################################\n","        # Discriminator B\n","        optimizer_D_B.zero_grad()\n","\n","        real_loss_Y = GAN_LOSS(disc_realY, valid)\n","        fake_loss_Y = GAN_LOSS(disc_fakeY.detach(), fake)\n","        loss_D_B = (real_loss_Y+fake_loss_Y)/2\n","\n","        loss_D_B.backward() \n","        optimizer_D_B.step()\n","        ####################################\n","        loss_D = (loss_D_A+loss_D_B)/2\n","        loss = loss_G + loss_D \n","        #loss.backward(retain_graph=True)\n","        ####################################\n","        #with torch.no_grad():\n","        #print(disc_fakeY)\n","        psnr = PSNR(img_fakeY.detach()[0].cpu().numpy(),img_realY.detach()[0].cpu().numpy())\n","        #print(psnr.item())\n","        ssim = SSIM(img_fakeY.detach()[0].permute(1,2,0).cpu().numpy(),img_realY.detach()[0].permute(1,2,0).cpu().numpy(),multichannel=True) \n","        #ignite.metrics.SSIM\n","        #predict = torch.argmax(disc_fakeY, dim=-1)\n","        #original = torch.argmax(disc_realY, dim=-1)\n","        #acc = np.mean((original == predict).cpu().numpy())\n","        #train_acc.append(acc)\n","        train_psnr.append(psnr)\n","        train_ssim.append(ssim)\n","        train_loss.append(loss.item())\n","        print('[Train Epoch %d/%d] [Batch %d/%d] [D loss : %4f] [G loss : %4f - (adv : %4f, cycle : %4f, identity : %4f)]'\n","                %(epoch+1,EPOCH_NUM,       # [Epoch -]\n","                    idx+1,len(train_loader),   # [Batch -]\n","                    loss_D.item(),       # [D loss -]\n","                    loss_G.item(),       # [G loss -]\n","                    gan_loss_t.item(),     # [adv -]\n","                    cyc_loss_t.item(),   # [cycle -]\n","                    cyc_loss_t.item(),# [identity -]\n","                    ))\n","################################################################################\n","def valid(valid_loader, G_AB, G_BA, D_A, D_B, \n","          IDENTITY_LOSS, GAN_LOSS, CYCLE_LOSS,\n","          use_gpu=True):\n","    #with torch.no_grad():\n","    valid_loss = []\n","    #valid_acc = []\n","    valid_psnr = []\n","    valid_ssim = []\n","    for idx, batch in enumerate(tqdm(valid_loader)):\n","        if use_gpu:\n","            img_realX = batch['A'].to(device)\n","            img_realY = batch['B'].to(device)\n","            valid = torch.cuda.FloatTensor(np.ones((img_realX.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n","            fake = torch.cuda.FloatTensor(np.zeros((img_realX.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n","        G_AB.eval()\n","        G_BA.eval()\n","        ####################################\n","        # Generator\n","        optimizer_G.zero_grad()\n","\n","        img_fakeY = G_AB(img_realX)\n","        img_cycledX = G_BA(img_fakeY)\n","        img_fakeX = G_BA(img_realY)\n","        img_cycledY = G_AB(img_fakeX)\n","\n","        disc_realX = D_A(img_realX)\n","        disc_realY = D_B(img_realY)\n","        disc_fakeX = D_A(img_fakeX)\n","        disc_fakeY = D_B(img_fakeY)\n","\n","        # Identity Loss\n","        id_loss_X = IDENTITY_LOSS(img_fakeX, img_realX)\n","        id_loss_Y = IDENTITY_LOSS(img_fakeY, img_realY)\n","        id_loss_t = (id_loss_X+id_loss_Y)/2\n","        # GAN Loss\n","        gan_loss_XY = GAN_LOSS(disc_fakeY, valid)\n","        gan_loss_YX = GAN_LOSS(disc_fakeX, valid)\n","        gan_loss_t  = (gan_loss_XY+gan_loss_YX)/2\n","        # Cycle Loss\n","        cyc_loss_X = CYCLE_LOSS(img_cycledX, img_realX)\n","        cyc_loss_Y = CYCLE_LOSS(img_cycledY, img_realX)\n","        cyc_loss_t = (cyc_loss_X+cyc_loss_Y)/2\n","        # Generator Total Loss\n","        loss_G = (5.0*id_loss_t) + gan_loss_t + (10.0*cyc_loss_t)\n","\n","        loss_G.backward()\n","        optimizer_G.step()\n","        ####################################\n","        # Discriminator A\n","        optimizer_D_A.zero_grad()\n","\n","        real_loss_X = GAN_LOSS(disc_realX, valid)\n","        fake_loss_X = GAN_LOSS(disc_fakeX.detach(), fake)\n","        loss_D_A = (real_loss_X+fake_loss_X)/2\n","\n","        loss_D_A.backward() \n","        optimizer_D_A.step()\n","        ####################################\n","        # Discriminator B\n","        optimizer_D_B.zero_grad()\n","\n","        real_loss_Y = GAN_LOSS(disc_realY, valid)\n","        fake_loss_Y = GAN_LOSS(disc_fakeY.detach(), fake)\n","        loss_D_B = (real_loss_Y+fake_loss_Y)/2\n","        \n","        loss_D_B.backward() \n","        optimizer_D_B.step()\n","        ####################################\n","        loss_D = (loss_D_A+loss_D_B)/2\n","        loss = loss_G + loss_D \n","        #loss.backward(retain_graph=True)\n","        ####################################\n","        #print(disc_fakeY)\n","        psnr = PSNR(img_fakeY.detach()[0].cpu().numpy(),img_realY.detach()[0].cpu().numpy())\n","        #print(psnr.item())\n","        ssim = SSIM(img_fakeY.detach()[0].permute(1,2,0).cpu().numpy(),img_realY.detach()[0].permute(1,2,0).cpu().numpy(),multichannel=True) \n","        #ignite.metrics.SSIM\n","        #predict = torch.argmax(disc_fakeY, dim=-1)\n","        #original = torch.argmax(disc_realY, dim=-1)\n","        #acc = np.mean((original == predict).cpu().numpy())\n","        #train_acc.append(acc)\n","        valid_psnr.append(psnr)\n","        valid_ssim.append(ssim)\n","        valid_loss.append(loss.item())\n","        print('[Valid Epoch %d/%d] [Batch %d/%d] [D loss : %4f] [G loss : %4f - (adv : %4f, cycle : %4f, identity : %4f)]'\n","                %(epoch+1,EPOCH_NUM,       # [Epoch -]\n","                idx+1,len(valid_loader),   # [Batch -]\n","                loss_D.item(),       # [D loss -]\n","                loss_G.item(),       # [G loss -]\n","                gan_loss_t.item(),     # [adv -]\n","                cyc_loss_t.item(),   # [cycle -]\n","                cyc_loss_t.item(),# [identity -]\n","                ))\n","    return np.mean(valid_psnr), np.mean(valid_ssim), np.mean(valid_loss)\n","\n","def save_checkpoint(valid_loss, loss_record, epoch, CKP_PATHA=CKP_PATHA, prefix='model'):\n","    # you can define the condition to save model :)\n","    #print(ssim_record[-5:].shape)\n","    #print(np.mean(ssim_record[-5:]))\n","    if valid_loss <= np.mean(loss_record[-5:]):    \n","        checkpoint_pathG_AB = CKP_PATHA+f'{\"G_AB\"}.pth'\n","        checkpoint_pathG_BA = CKP_PATHA+f'{\"G_BA\"}.pth'\n","        torch.save(G_AB.state_dict(), checkpoint_pathG_AB)\n","        print('model saved to %s' % checkpoint_pathG_AB)\n","        torch.save(G_BA.state_dict(), checkpoint_pathG_BA)\n","        print('model saved to %s' % checkpoint_pathG_BA)\n","\n","def better(loss_record):\n","    if min(loss_record) == loss_record[-1]: return True\n","    return False"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4-c valid"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4-d Learing Schedule"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LambdaLR:\n","    def __init__(self, n_epochs, offset, decay_start_epoch):\n","        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n","        self.n_epochs = n_epochs\n","        self.offset = offset\n","        self.decay_start_epoch = decay_start_epoch\n","        \n","    def step(self, epoch):\n","        return 1.0 - max(0, epoch+self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# n_epochs = 10\n","# epoch = 0\n","# decay_epoch = 5\n","\n","\"\"\"\n","lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_G,\n","    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",")\n","\n","lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_D_A,\n","    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",")\n","lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_D_B,\n","    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",")\n","\"\"\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### main"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T13:29:27.717263Z","iopub.status.busy":"2023-07-22T13:29:27.716898Z"},"trusted":true},"outputs":[],"source":["import itertools\n","if __name__ == '__main__':\n","  G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n","  G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n","  #G = GeneratorResNet(input_shape, n_residual_blocks)\n","  D_A = Discriminator(input_shape)\n","  D_B = Discriminator(input_shape)\n","  G_AB.apply(weights_init)\n","  G_BA.apply(weights_init)\n","  D_A.apply(weights_init)\n","  D_B.apply(weights_init)\n","  #metric = StructuralSimilarityIndexMeasure()\n","  if USE_GPU:\n","    G_AB.to(device)\n","    G_BA.to(device)\n","    #G.to(device)\n","    D_A.to(device)\n","    D_B.to(device)\n","    #PSNR = PSNR()\n","    #SSIM = SSIM().to(device)\n","    #metric.to(device)\n","    #optimizerG_AB = torch.optim.Adam(G_AB.parameters(), lr=0.001)\n","    #optimizerG_BA = torch.optim.Adam(G_BA.parameters(), lr=0.001)\n","    optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=LR, betas=(BETA1,BETA2))\n","    optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=LR, betas=(BETA1,BETA2))\n","    optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=LR, betas=(BETA1,BETA2))\n","    #optimizer = torch.optim.SGD(model.parameters(), lr=0.009, momentum=0.8)#lr=0.009\n","    #loss_fn = nn.CrossEntropyLoss()\n","    \n","    #acc_record = []\n","    #ssim_record = []\n","    loss_record = []\n","    \n","    for epoch in range(EPOCH_START, EPOCH_NUM):\n","      train(train_loader, G_AB, G_BA, D_A, D_B, \n","          IDENTITY_LOSS, GAN_LOSS, CYCLE_LOSS,\n","          USE_GPU)\n","      valid_psnr,valid_ssim, valid_loss =  \\\n","      valid(valid_loader, G_AB, G_BA, D_A, D_B, \n","          IDENTITY_LOSS, GAN_LOSS, CYCLE_LOSS,\n","          USE_GPU)\n","      #acc_record.append(valid_acc)\n","      loss_record.append(valid_loss)\n","      #print(\"ssim_record: \",ssim_record.shape)\n","      #print(\"ssim_record: \",valid_ssim.shape)\n","        \n","      if better(loss_record):\n","        save_checkpoint(valid_loss, loss_record, epoch, prefix='model')\n","        \n","      print('########################################################')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 5. Test Process"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DEVICE_ID = 0\n","torch.cuda.set_device(DEVICE_ID)\n","USE_GPU = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_GPU else \"cpu\")\n","import torch\n","from torchmetrics.image import StructuralSimilarityIndexMeasure\n","#from piqa import PSNR, SSIM\n","import skimage\n","from skimage.metrics import structural_similarity as SSIM\n","from skimage.metrics import peak_signal_noise_ratio as PSNR"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torchvision.utils import save_image\n","def test(test_loader, model,TST_PATHB=TST_PATHB, use_gpu=True):\n","    with torch.no_grad():\n","        #predict_result = []\n","        #predict_name = []\n","        for idx, batch in enumerate(tqdm(test_loader)):\n","        #for (img_realX, img_realXName) in test_loader:\n","            if use_gpu:\n","                img_realX = batch['A'].to(device)\n","                img_realXName = batch['Name'][0]\n","            img_fakeY = model(img_realX)\n","            img_output = img_fakeY.squeeze()\n","            save_image(img_output, os.path.join(TST_PATHB,img_realXName),normalize=True)\n","            #predict = torch.argmax(output, dim=-1).tolist()\n","            #predict_result += predict\n","            #predict_name += name\n","    \"\"\"    \n","    with open(file_name, 'w', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerow(['id', 'label'])\n","        for id, r in zip(predict_name, predict_result):\n","            writer.writerow([id, r])\n","    \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#del G_AB\n","G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n","G_AB.load_state_dict(torch.load('G_AB.pth'))\n","G_AB = G_AB.cuda()\n","test(test_loader, G_AB, TST_PATHB, USE_GPU)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":4}
